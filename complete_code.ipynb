{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Agustin CARTAYA\n",
    "\n",
    "# matrix and tables gestion\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train test separation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scalers\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier    \n",
    "\n",
    "# features selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "\n",
    "# -------- datasets\n",
    "# dataset ADCTL\n",
    "DATASET_ADCTL = \"ADCTL\"\n",
    "LABELS_ADCTL = (\"CTL\", \"AD\")\n",
    "\n",
    "# dataset ADMCI\n",
    "DATASET_ADMCI = \"ADMCI\"\n",
    "LABELS_ADMCI = (\"MCI\", \"AD\")\n",
    "\n",
    "# dataset MCICT\n",
    "DATASET_MCICTL = \"MCICTL\"\n",
    "LABELS_MCICTL = (\"CTL\", \"MCI\")\n",
    "\n",
    "# -------- functions\n",
    "def get_dataset_class_labels(dataset):\n",
    "    label_classes=\"\"\n",
    "    if dataset == DATASET_ADCTL:\n",
    "        label_classes = LABELS_ADCTL\n",
    "    elif dataset == DATASET_ADMCI :\n",
    "        label_classes = LABELS_ADMCI\n",
    "    elif dataset == DATASET_MCICTL :\n",
    "        label_classes = LABELS_MCICTL\n",
    "    return label_classes\n",
    "\n",
    "def read_data(dataset=\"ADCTL\", data_type=\"train\"):\n",
    "    extension = \".csv\"    \n",
    "    path = \"data/\" + dataset + data_type + extension\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    label_classes = get_dataset_class_labels(dataset)\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        data['Label'] = data['Label'].replace({label_classes[0]: 0, label_classes[1]: 1})\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_best_params(dataset):\n",
    "    best_result_knn = []\n",
    "    best_result_svm = []\n",
    "\n",
    "    best_result_knn_keys = [\"train_acc\",\"test_acc\",\"train_auc\",\"test_auc\",\"f_classif\",\"mutual_info_classif\",\"pca\",\"n_neighbors\",\"p\"]\n",
    "    best_result_svm_keys = [\"train_acc\",\"test_acc\",\"train_auc\",\"test_auc\",\"f_classif\",\"mutual_info_classif\",\"pca\",\"C\",\"degree\", \"kernel\"]\n",
    "    ## best results DATASET_ADCTL\n",
    "    if dataset == DATASET_ADCTL:\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca    n_neighbors    p\n",
    "        best_result_knn =    [0.96748,       0.926829,       0.99496,    0.964976,          1,                 358,      9,             3,   1]\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca      C  degree   kernel\n",
    "        best_result_svm =   [1.0,           0.902439,           1.0,    0.983092,           1,                 247,    119,   0.1,      1,  \"poly\"]\n",
    "\n",
    "    ## best results DATASET_ADMCI\n",
    "    elif dataset == DATASET_ADMCI:\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca    n_neighbors    p\n",
    "        best_result_knn =    [0.891473,       0.72093,       0.974687,    0.780303,          6,                 43,      19,            2,   1]\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca      C  degree   kernel\n",
    "        best_result_svm =   [0.868217,       0.651163,      0.943587,    0.733766,         53,                   50,    50,   1.0,      1,  \"poly\"]\n",
    "\n",
    "    ## best results DATASET_MCICTL\n",
    "    elif dataset == DATASET_MCICTL:\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca    n_neighbors    p\n",
    "        best_result_knn =   [0.968992,       0.906977,      0.998074,     0.96087,          1,                  172,    61,             3,   1]\n",
    "        #                   train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca      C  degree   kernel\n",
    "        best_result_svm =   [0.953488,       0.883721,       0.98676,    0.956522,          1,                 172,     51,   0.1,      1,  \"poly\"]\n",
    "     \n",
    "    return dict(zip(best_result_knn_keys, best_result_knn)), dict(zip(best_result_svm_keys, best_result_svm))\n",
    "\n",
    "def get_freatures_labels_training(data):\n",
    "    x_tr=data.drop(['Label', 'ID'],axis=1)\n",
    "    y_tr=pd.DataFrame(data.Label, columns = ['Label'])\n",
    "    return (x_tr, y_tr)\n",
    "\n",
    "def split_trainin(x_tr, y_tr, test_size=0.25, random_state=42, shuffle=False):\n",
    "    return train_test_split(x_tr, y_tr, test_size=test_size, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "def normalize_training_test(x_train, x_test):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x_train_normalized = scaler.fit_transform(x_train)\n",
    "    x_test_normalized = scaler.transform(x_test)\n",
    "    return x_train_normalized, x_test_normalized\n",
    "\n",
    "def feature_selection(x_train, x_test, y_train, i_f_classif, i_mutual_info_classif, features_index=False):\n",
    "    # individual features selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=i_f_classif)\n",
    "    selector.fit(x_train, y_train)\n",
    "\n",
    "    features_selected_f_classif = selector.get_support(indices=True)\n",
    "    # print(\"f classif features selection: \\n\", features_selected_f_classif)\n",
    "\n",
    "    # multiple features selection\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=i_mutual_info_classif)\n",
    "    selector.fit(x_train, y_train)\n",
    "\n",
    "    features_selected_mutual_info_classif  = selector.get_support(indices=True)\n",
    "    # print(\"mutual info classif features selection: \\n\",features_selected_mutual_info_classif)\n",
    "\n",
    "    # union of selected features\n",
    "    conjunto = list(set(features_selected_f_classif) | set(features_selected_mutual_info_classif))\n",
    "    # print(\"Selected features = \", len(conjunto), \"\\n\", conjunto)\n",
    "\n",
    "    if features_index:\n",
    "        return (x_train[:, conjunto], x_test[:, conjunto], conjunto)\n",
    "    else:\n",
    "        return (x_train[:, conjunto], x_test[:, conjunto])\n",
    "\n",
    "def apply_PCA(x_train, x_test, pca_components):\n",
    "    pca = PCA(pca_components)\n",
    "    x_train_pca = pca.fit_transform(x_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "    return (x_train_pca, x_test_pca)\n",
    "    \n",
    "def apply_lda(x_train, x_test, y_train):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "    x_train_lda = lda.fit_transform(x_train, y_train)\n",
    "    x_test_lda = lda.transform(x_test)                                                                           \n",
    "    return (x_train_lda, x_test_lda)\n",
    "\n",
    "def compute_scores(y, y_pred, y_pred_probability):\n",
    "    # calculate the cofusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    # Accuracy\n",
    "    acc = (tp+tn)/(tn + fp + fn + tp)\n",
    "    # specificity\n",
    "    spec = tn / (tn + fp)\n",
    "    # sensitivity (recall)\n",
    "    sens = tp / (tp + fn)\n",
    "    # presition\n",
    "    prec  = tp/(tp+fp)  \n",
    "    # f1\n",
    "    f1 = (2 * prec * sens)/(prec + sens)\n",
    "    # ba\n",
    "    ba = (spec + sens)/2\n",
    "    # mcc\n",
    "    mcc = matthews_corrcoef(y, y_pred)\n",
    "    #auc\n",
    "    auc = roc_auc_score(y, y_pred_probability)\n",
    "    \n",
    "    return {\"tn\":tn, \"fp\":fp, \"fn\":fn, \"tp\":fn, \"acc\":acc, \"spec\":spec, \"sens\":sens, \"prec\":prec, \"f1\":f1, \"ba\":ba, \"auc\":auc, \"mcc\":mcc}\n",
    "\n",
    "def combine_prediction(probabilities, weights):\n",
    "    weights_sum = sum(weights)\n",
    "    normalized_weights = np.array([[weight / weights_sum for weight in weights]]).T\n",
    "    y_lineal_combination = np.dot(np.array(probabilities).T, normalized_weights)\n",
    "    y_predicted = np.where(y_lineal_combination > 0.5, 1, 0)\n",
    "    \n",
    "    return y_predicted, y_lineal_combination\n",
    "\n",
    "def create_csv_output(dataset, ids, predicted_classes, predicted_probabilities):\n",
    "    predicted_probabilities_complement = 1 - predicted_probabilities\n",
    "    \n",
    "    df = pd.DataFrame({ 'id': ids.flatten(), \n",
    "                        'class': predicted_classes.flatten(),\n",
    "                        'predicted_probability_'+ get_dataset_class_labels(dataset)[0]: predicted_probabilities_complement.flatten(), \n",
    "                        'predicted_probability_'+ get_dataset_class_labels(dataset)[1]: predicted_probabilities.flatten()})\n",
    "    \n",
    "    df.to_csv('0075721_CartayaLathulerie_'+ dataset +'res.csv', index=False)\n",
    "\n",
    "def create_csv_selected_features(dataset, features_selected):\n",
    "    df = pd.DataFrame(features_selected, columns=['features_selected'])\n",
    "    df.to_csv('0075721_CartayaLathulerie_'+ dataset +'feat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_approach():\n",
    "    # DATASET_ADCTL DATASET_ADMCI DATASET_MCICTL\n",
    "    columns = [\"DATASET\", \"Acc\", \"Sens\", \"Spec\", \"Prec\", \"F1\", \"AUC\", \"MCC\", \"BA\"]\n",
    "    train_table =  pd.DataFrame(columns=columns)\n",
    "    test_table =  pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "    for dataset in [DATASET_ADCTL, DATASET_ADMCI, DATASET_MCICTL]:\n",
    "        \n",
    "        # select best parameters\n",
    "        params_knn, params_svm  = get_best_params(dataset)\n",
    "        # read data training data\n",
    "        data = read_data(dataset=dataset, data_type=\"train\")\n",
    "        # obtaining labels and features from training data\n",
    "        x_tr, y_tr = get_freatures_labels_training(data)\n",
    "        # split into train and test\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(x_tr, y_tr, test_size=0.25, shuffle=True, random_state=42)\n",
    "        # normalize data\n",
    "        x_train_normalized, x_test_normalized = normalize_training_test(x_train, x_test)\n",
    "\n",
    "        # ---- KNN\n",
    "        # feature selection\n",
    "        knn_x_train_selected, knn_x_test_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_knn[\"f_classif\"], params_knn[\"mutual_info_classif\"])\n",
    "        # obtaining the first n principal components\n",
    "        knn_x_train_pca, knn_x_test_pca = apply_PCA(knn_x_train_selected, knn_x_test_selected, params_knn[\"pca\"])\n",
    "        # apply LDA\n",
    "        knn_x_train_lda, knn_x_test_lda = apply_lda(knn_x_train_pca, knn_x_test_pca, y_train)\n",
    "        # create and train the classifier\n",
    "        knn_classifier = KNeighborsClassifier(n_neighbors=int(params_knn[\"n_neighbors\"]), p=params_knn[\"p\"])\n",
    "        knn_classifier.fit(knn_x_train_lda, y_train)\n",
    "        knn_y_predcted_probability_test = knn_classifier.predict_proba(knn_x_test_lda)[:, 1]\n",
    "        knn_y_predcted_probability_train = knn_classifier.predict_proba(knn_x_train_lda)[:, 1]\n",
    "\n",
    "        # ---- SVM\n",
    "        # feature selection\n",
    "        svm_x_train_selected, svm_x_test_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_svm[\"f_classif\"], params_svm[\"mutual_info_classif\"])\n",
    "        # obtaining the first n principal components\n",
    "        svm_x_train_pca, svm_x_test_pca = apply_PCA(svm_x_train_selected, svm_x_test_selected, params_svm[\"pca\"])\n",
    "        # apply LDA\n",
    "        svm_x_train_lda, svm_x_test_lda = apply_lda(svm_x_train_pca, svm_x_test_pca, y_train)\n",
    "        # create and train the classifier\n",
    "        svm_classifier = SVC(C=params_svm[\"C\"], degree=params_svm[\"degree\"], kernel=params_svm[\"kernel\"], probability=True)\n",
    "        svm_classifier.fit(svm_x_train_lda, y_train)\n",
    "        svm_y_predcted_probability_test = svm_classifier.predict_proba(svm_x_test_lda)[:, 1]\n",
    "        svm_y_predcted_probability_train = svm_classifier.predict_proba(svm_x_train_lda)[:, 1]\n",
    "\n",
    "        weights = [params_knn[\"test_auc\"], params_svm[\"test_auc\"]]\n",
    "        y_pred_test, y_pred_probability_test = combine_prediction([knn_y_predcted_probability_test, svm_y_predcted_probability_test],  weights)\n",
    "        y_pred_train, y_pred_probability_train = combine_prediction([knn_y_predcted_probability_train, svm_y_predcted_probability_train],  weights)\n",
    "        \n",
    "        # computing scores\n",
    "        s_ts = compute_scores(y_test, y_pred_test, y_pred_probability_test)\n",
    "        s_tr = compute_scores(y_train, y_pred_train, y_pred_probability_train)\n",
    "\n",
    "        test_table = test_table.append(pd.Series([dataset, s_ts[\"acc\"], s_ts[\"sens\"], s_ts[\"spec\"], s_ts[\"prec\"], s_ts[\"f1\"], s_ts[\"auc\"], s_ts[\"mcc\"], s_ts[\"ba\"]], index=columns),\n",
    "                                        ignore_index=True)\n",
    "        train_table = train_table.append(pd.Series([dataset, s_tr[\"acc\"], s_tr[\"sens\"], s_tr[\"spec\"], s_tr[\"prec\"], s_tr[\"f1\"], s_tr[\"auc\"], s_tr[\"mcc\"], s_tr[\"ba\"]], index=columns),\n",
    "                                        ignore_index=True)\n",
    "\n",
    "    print(\"\\nPerformance on the 75% of the training datasets (data used for training the model):\")\n",
    "    print(train_table.head())\n",
    "\n",
    "    print(\"\\nPerformance on the 25% of the training dataset (data not used for training the models):\")\n",
    "    print(test_table.head())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_approach_with_cross_validation(k=5, choose=\"MEAN\"):\n",
    "    columns = [\"DATASET\", \"Acc\", \"Sens\", \"Spec\", \"Prec\", \"F1\", \"AUC\", \"MCC\", \"BA\"]\n",
    "    cross_validation_table =  pd.DataFrame(columns=columns)\n",
    "\n",
    "    for dataset in [DATASET_ADCTL, DATASET_ADMCI, DATASET_MCICTL]:\n",
    "\n",
    "        # read data training data\n",
    "        data = read_data(dataset=dataset, data_type=\"train\")\n",
    "        # shuffle data\n",
    "        data = data.sample(frac=1, random_state=42)\n",
    "        # obtaining labels and features from training data\n",
    "        x_tr, y_tr = get_freatures_labels_training(data)\n",
    "        # select best parameters\n",
    "        params_knn, params_svm  = get_best_params(dataset)\n",
    "        # divide folds\n",
    "        x_folds = np.array_split(x_tr, k)\n",
    "        y_folds = np.array_split(y_tr, k)\n",
    "        scores = []\n",
    "\n",
    "        # cross validation\n",
    "        for i in range(k):\n",
    "            # obtain train and test\n",
    "            x_train = np.concatenate(x_folds[:i] + x_folds[i+1:])\n",
    "            y_train = np.concatenate(y_folds[:i] + y_folds[i+1:])\n",
    "            x_test = x_folds[i]\n",
    "            y_test = y_folds[i]\n",
    "\n",
    "            # normalize data\n",
    "            x_train_normalized, x_test_normalized = normalize_training_test(x_train, x_test)\n",
    "\n",
    "            # ---- KNN\n",
    "            # feature selection\n",
    "            knn_x_train_selected, knn_x_test_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_knn[\"f_classif\"], params_knn[\"mutual_info_classif\"])\n",
    "            # obtaining the first n principal components\n",
    "            knn_x_train_pca, knn_x_test_pca = apply_PCA(knn_x_train_selected, knn_x_test_selected, params_knn[\"pca\"])\n",
    "            # apply LDA\n",
    "            knn_x_train_lda, knn_x_test_lda = apply_lda(knn_x_train_pca, knn_x_test_pca, y_train)\n",
    "            # create and train the classifier\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=int(params_knn[\"n_neighbors\"]), p=params_knn[\"p\"])\n",
    "            knn_classifier.fit(knn_x_train_lda, y_train)\n",
    "            knn_y_predcted_probability = knn_classifier.predict_proba(knn_x_test_lda)[:, 1]\n",
    "            knn_y_predcted = knn_classifier.predict(knn_x_test_lda)\n",
    "\n",
    "            # ---- SVM\n",
    "            # feature selection\n",
    "            svm_x_train_selected, svm_x_test_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_svm[\"f_classif\"], params_svm[\"mutual_info_classif\"])\n",
    "            # obtaining the first n principal components\n",
    "            svm_x_train_pca, svm_x_test_pca = apply_PCA(svm_x_train_selected, svm_x_test_selected, params_svm[\"pca\"])\n",
    "            # apply LDA\n",
    "            svm_x_train_lda, svm_x_test_lda = apply_lda(svm_x_train_pca, svm_x_test_pca, y_train)\n",
    "            # create and train the classifier\n",
    "            svm_classifier = SVC(C=params_svm[\"C\"], degree=params_svm[\"degree\"], kernel=params_svm[\"kernel\"], probability=True)\n",
    "            svm_classifier.fit(svm_x_train_lda, y_train)\n",
    "            svm_y_predcted_probability = svm_classifier.predict_proba(svm_x_test_lda)[:, 1]\n",
    "            svm_y_predcted = svm_classifier.predict(svm_x_test_lda)\n",
    "\n",
    "            weights = [params_knn[\"test_auc\"], params_svm[\"test_auc\"]]\n",
    "            y_pred_test, y_pred_probability_test = combine_prediction([knn_y_predcted_probability, svm_y_predcted_probability],  weights)\n",
    "            \n",
    "            # computing scores\n",
    "            scd = compute_scores(y_test, y_pred_test, y_pred_probability_test)\n",
    "            scores.append((scd[\"acc\"], scd[\"sens\"], scd[\"spec\"], scd[\"prec\"], scd[\"f1\"], scd[\"auc\"], scd[\"mcc\"], scd[\"ba\"]))\n",
    "\n",
    "        # calc scores means\n",
    "        scores = np.nan_to_num(scores)\n",
    "        scores = np.array(scores)\n",
    "        if choose == \"MAX\":\n",
    "            scores_choosen = scores[scores[:, 5].argmax(), :]\n",
    "        else:\n",
    "            scores_choosen = np.mean(scores, axis=0).tolist()\n",
    "\n",
    "        cross_validation_table = cross_validation_table.append(pd.Series([dataset, *scores_choosen], index=columns), ignore_index=True)\n",
    "\n",
    "    print(choose, \"\\nPerformance of the classifiers using 5-fold cross validation:\")\n",
    "    print(cross_validation_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_dataset():\n",
    "    columns = [\"DATASET\", \"Acc\", \"Sens\", \"Spec\", \"Prec\", \"F1\", \"AUC\", \"MCC\", \"BA\"]\n",
    "    train_table =  pd.DataFrame(columns=columns)\n",
    "    for dataset in [DATASET_ADCTL, DATASET_ADMCI, DATASET_MCICTL]:\n",
    "        # select best parameters\n",
    "        params_knn, params_svm  = get_best_params(dataset)\n",
    "\n",
    "        # read train dataset\n",
    "        data_tr = read_data(dataset=dataset, data_type=\"train\")\n",
    "\n",
    "        # read test dataset\n",
    "        data_ts = read_data(dataset=dataset, data_type=\"test\")\n",
    "\n",
    "        # obtaining labels and features from training data\n",
    "        x_train, y_train = get_freatures_labels_training(data_tr)\n",
    "\n",
    "        # remove and save id from test data\n",
    "        x_test=data_ts.drop(['ID'],axis=1)\n",
    "        id_test=np.array([data_ts.ID]).T\n",
    "\n",
    "        # normalize data\n",
    "        x_train_normalized, x_test_normalized = normalize_training_test(x_train, x_test)\n",
    "\n",
    "        # ---- KNN\n",
    "        # feature selection\n",
    "        knn_x_train_selected, knn_x_test_selected, knn_features_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_knn[\"f_classif\"], params_knn[\"mutual_info_classif\"], features_index=True)\n",
    "        # obtaining the first n principal components\n",
    "        knn_x_train_pca, knn_x_test_pca = apply_PCA(knn_x_train_selected, knn_x_test_selected, params_knn[\"pca\"])\n",
    "        # apply LDA\n",
    "        knn_x_train_lda, knn_x_test_lda = apply_lda(knn_x_train_pca, knn_x_test_pca, y_train)\n",
    "        # create and train the classifier\n",
    "        knn_classifier = KNeighborsClassifier(n_neighbors=int(params_knn[\"n_neighbors\"]), p=params_knn[\"p\"])\n",
    "        knn_classifier.fit(knn_x_train_lda, y_train)\n",
    "        knn_y_predcted_probability = knn_classifier.predict_proba(knn_x_test_lda)[:, 1]\n",
    "        knn_y_predcted_probability_train = knn_classifier.predict_proba(knn_x_train_lda)[:, 1]\n",
    "\n",
    "        # ---- SVM\n",
    "        # feature selection\n",
    "        svm_x_train_selected, svm_x_test_selected, svm_features_selected = feature_selection(x_train_normalized, x_test_normalized, y_train, params_svm[\"f_classif\"], params_svm[\"mutual_info_classif\"], features_index=True)\n",
    "        # obtaining the first n principal components\n",
    "        svm_x_train_pca, svm_x_test_pca = apply_PCA(svm_x_train_selected, svm_x_test_selected, params_svm[\"pca\"])\n",
    "        # apply LDA\n",
    "        svm_x_train_lda, svm_x_test_lda = apply_lda(svm_x_train_pca, svm_x_test_pca, y_train)\n",
    "        # create and train the classifier\n",
    "        svm_classifier = SVC(C=params_svm[\"C\"], degree=params_svm[\"degree\"], kernel=params_svm[\"kernel\"], probability=True)\n",
    "        svm_classifier.fit(svm_x_train_lda, y_train)\n",
    "        svm_y_predcted_probability = svm_classifier.predict_proba(svm_x_test_lda)[:, 1]\n",
    "        svm_y_predcted_probability_train = svm_classifier.predict_proba(svm_x_train_lda)[:, 1]\n",
    "\n",
    "        weights = [params_knn[\"test_auc\"], params_svm[\"test_auc\"]]\n",
    "        # weights = [1, 1]\n",
    "        y_pred_test, y_pred_probability_test = combine_prediction([knn_y_predcted_probability, svm_y_predcted_probability],  weights)\n",
    "        y_pred_train, y_pred_probability_train = combine_prediction([knn_y_predcted_probability_train, svm_y_predcted_probability_train],  weights)\n",
    "        \n",
    "        # computing training scores\n",
    "        scd = compute_scores(y_train, y_pred_train, y_pred_probability_train)\n",
    "\n",
    "        train_table = train_table.append(pd.Series([dataset, scd[\"acc\"], scd[\"sens\"], scd[\"spec\"], scd[\"prec\"], scd[\"f1\"], scd[\"auc\"], scd[\"mcc\"], scd[\"ba\"]], index=columns),\n",
    "                                                ignore_index=True)\n",
    "\n",
    "        # creating csv files\n",
    "        create_csv_output(dataset, id_test, y_pred_test, y_pred_probability_test)\n",
    "        # combine selected features by the two clasifiers\n",
    "        features_selected = list(set(svm_features_selected) | set(knn_features_selected))\n",
    "        create_csv_selected_features(dataset, features_selected)\n",
    "\n",
    "    print(\"\\nPerformance on the 100% of the training datasets (data used for training the model):\")\n",
    "    print(train_table.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN \n",
      "Performance of the classifiers using 5-fold cross validation:\n",
      "  DATASET       Acc      Sens      Spec      Prec        F1       AUC       MCC        BA\n",
      "0   ADCTL  0.847538  0.865441  0.822745  0.854880  0.855395  0.924329  0.700672  0.844093\n",
      "1   ADMCI  0.686555  0.659649  0.721287  0.689615  0.667559  0.719654  0.383355  0.690468\n",
      "2  MCICTL  0.790252  0.814524  0.763636  0.780658  0.793094  0.874777  0.578215  0.789080\n",
      "\n",
      "Performance on the 75% of the training datasets (data used for training the model):\n",
      "  DATASET       Acc      Sens      Spec      Prec        F1      AUC       MCC        BA\n",
      "0   ADCTL  1.000000  1.000000  1.000000  1.000000  1.000000  1.00000  1.000000  1.000000\n",
      "1   ADMCI  0.914729  0.918033  0.911765  0.903226  0.910569  0.98216  0.829198  0.914899\n",
      "2  MCICTL  0.961240  0.970149  0.951613  0.955882  0.962963  0.99687  0.922429  0.960881\n",
      "\n",
      "Performance on the 25% of the training dataset (data not used for training the models):\n",
      "  DATASET       Acc      Sens      Spec      Prec        F1       AUC       MCC        BA\n",
      "0   ADCTL  0.902439  0.869565  0.944444  0.952381  0.909091  0.990338  0.808174  0.907005\n",
      "1   ADMCI  0.697674  0.666667  0.727273  0.700000  0.682927  0.792208  0.394795  0.696970\n",
      "2  MCICTL  0.930233  0.913043  0.950000  0.954545  0.933333  0.965217  0.861173  0.931522\n",
      "\n",
      "Performance on the 100% of the training datasets (data used for training the model):\n",
      "  DATASET       Acc      Sens      Spec      Prec        F1       AUC       MCC        BA\n",
      "0   ADCTL  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "1   ADMCI  0.883721  0.865854  0.900000  0.887500  0.876543  0.968157  0.766894  0.882927\n",
      "2  MCICTL  0.918605  0.922222  0.914634  0.922222  0.922222  0.982656  0.836856  0.918428\n"
     ]
    }
   ],
   "source": [
    "test_approach_with_cross_validation(k=5, choose=\"MEAN\")\n",
    "test_approach()\n",
    "predict_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def find_best_features_and_classifier(dataset):\n",
    "\n",
    "    def get_svm_gridsearch():\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        pipe_SVM = Pipeline([('classifier',SVC( ))])\n",
    "\n",
    "        parameters_SVM={\n",
    "                        'classifier__C': [0.1, 1, 10],\n",
    "                        'classifier__kernel': ['poly', 'rbf'],\n",
    "                        'classifier__degree': [1, 2, 3]\n",
    "                        }\n",
    "        grid_search_SVM = GridSearchCV(pipe_SVM, parameters_SVM, cv=cv)\n",
    "        return grid_search_SVM\n",
    "\n",
    "    def get_knn_gridsearch():\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        pipe_KNN = Pipeline([('classifier', KNeighborsClassifier(algorithm='ball_tree'))])\n",
    "\n",
    "        parameters_KNN={'classifier__n_neighbors': [1,2,3,4,5,6,7,8,9,10],\n",
    "                        'classifier__p': [1,2]}\n",
    "\n",
    "        grid_search_KNN = GridSearchCV(pipe_KNN, parameters_KNN, cv=cv)\n",
    "        return grid_search_KNN\n",
    "\n",
    "    def get_classifier_results(classifier, x_train, x_test, y_train, y_test):\n",
    "        # train\n",
    "        train_score = classifier.score(x_train, y_train)\n",
    "        y_pred_train = classifier.predict_proba(x_train)[:, 1]\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "        # test\n",
    "        test_score = classifier.score(x_test, y_test)\n",
    "        y_pred_test = classifier.predict_proba(x_test)[:, 1]\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "        return (train_score, auc_train, test_score, auc_test)\n",
    "    \n",
    "    grid_search_SVM = get_svm_gridsearch()\n",
    "    grid_search_KNN = get_knn_gridsearch()\n",
    "    def calc_svm_knn(x_train, x_test, y_train, y_test):\n",
    "        grid_search_SVM.fit(x_train, y_train)\n",
    "        grid_search_KNN.fit(x_train, y_train)\n",
    "\n",
    "        classifier_svm = SVC(C=grid_search_SVM.best_params_['classifier__C'], degree=grid_search_SVM.best_params_['classifier__degree'], kernel=grid_search_SVM.best_params_['classifier__kernel'], probability=True)\n",
    "        classifier_svm.fit(x_train, y_train)\n",
    "\n",
    "        classifier_knn = KNeighborsClassifier(n_neighbors=grid_search_KNN.best_params_['classifier__n_neighbors'], p=grid_search_KNN.best_params_['classifier__p'])\n",
    "        classifier_knn.fit(x_train, y_train)\n",
    "\n",
    "        svm_results = get_classifier_results(classifier_svm, x_train, x_test, y_train, y_test)\n",
    "        knn_results = get_classifier_results(classifier_knn, x_train, x_test, y_train, y_test)\n",
    "\n",
    "        return ((svm_results, grid_search_SVM.best_params_), (knn_results, grid_search_KNN.best_params_))\n",
    "\n",
    "    def prepare_data():\n",
    "        # read data training data\n",
    "        data = read_data(dataset=dataset, data_type=\"train\")\n",
    "\n",
    "        # obtaining labels and features from training data\n",
    "        x_tr, y_tr = get_freatures_labels_training(data)\n",
    "\n",
    "        # split into train and test\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(x_tr, y_tr, test_size=0.25, random_state=42)\n",
    "\n",
    "        # normalize data\n",
    "        x_train_normalized, x_test_normalized = normalize_training_test(x_train, x_test)\n",
    "        return (x_train_normalized, x_test_normalized, y_train, y_test)\n",
    "\n",
    "    def init_search():\n",
    "        x_train_normalized, x_test_normalized, y_train, y_test = prepare_data()\n",
    "        res_svm = []\n",
    "        res_knn = []\n",
    "        for i_f_classif in range(1, x_train_normalized.shape[1], 5):\n",
    "        # for i_f_classif in range(1, 2):\n",
    "\n",
    "            #  selecting individuals\n",
    "            selector = SelectKBest(score_func=f_classif, k=i_f_classif)\n",
    "            selector.fit(x_train_normalized, y_train)\n",
    "            features_selected_f_classif = selector.get_support(indices=True)\n",
    "\n",
    "            for i_mutual_info_classif in range(1,  x_train_normalized.shape[1], 5):\n",
    "            # for i_mutual_info_classif in range(358,  359):\n",
    "\n",
    "                # selecting multiples\n",
    "                selector = SelectKBest(score_func=mutual_info_classif, k=i_mutual_info_classif)\n",
    "                selector.fit(x_train_normalized, y_train)\n",
    "                features_selected_mutual_info_classif  = selector.get_support(indices=True)\n",
    "\n",
    "                conjunto = list(set(features_selected_f_classif) | set(features_selected_mutual_info_classif))\n",
    "                x_train_extracted_features = x_train_normalized[:, conjunto]\n",
    "                x_test_extracted_features = x_test_normalized[:, conjunto]\n",
    "\n",
    "                for i_pca in range(1, min(x_train_extracted_features.shape), 3):\n",
    "                # for i_pca in range(9, 10):\n",
    "\n",
    "                    # PCA\n",
    "                    pca = PCA(i_pca)\n",
    "                    x_train_pca = pca.fit_transform(x_train_extracted_features)\n",
    "                    x_test_pca = pca.transform(x_test_extracted_features)\n",
    "\n",
    "                    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "                    x_train_lda = lda.fit_transform(x_train_pca, y_train)\n",
    "                    x_test_lda = lda.transform(x_test_pca)        \n",
    "\n",
    "                    single_res_svm,  single_res_knn = calc_svm_knn(x_train_lda, x_test_lda, y_train, y_test)\n",
    "                    res_svm.append((*single_res_svm[0], i_f_classif, i_mutual_info_classif, i_pca, single_res_svm[1]['classifier__C'], single_res_svm[1]['classifier__degree'], single_res_svm[1]['classifier__kernel'] ))\n",
    "                    res_knn.append((*single_res_knn[0], i_f_classif, i_mutual_info_classif, i_pca, single_res_knn[1]['classifier__n_neighbors'], single_res_knn[1]['classifier__p'] ))\n",
    "\n",
    "                    print(i_f_classif, \" \", i_mutual_info_classif, \" \", i_pca , \n",
    "                        \" tr svm acc: \", single_res_svm[0][0], \" tr svm AUC: \", single_res_svm[0][1],\n",
    "                        \" ts svm acc: \", single_res_svm[0][2], \" ts svm AUC: \", single_res_svm[0][3],\n",
    "                        \" tr knn acc: \", single_res_knn[0][0], \" tr knn AUC: \", single_res_knn[0][1],  \n",
    "                        \" ts knn acc: \", single_res_knn[0][2], \" ts knn AUC: \", single_res_knn[0][3])\n",
    "\n",
    "        res_svm = pd.DataFrame(res_svm,\n",
    "                             columns=[\"train_acc\", \"train_auc\", \"test_acc\", \"test_auc\", \"f_classif\", \"mutual_info_classif\", \"pca\", \"c\", \"degree\", \"kernel\"])\n",
    "\n",
    "        res_knn = pd.DataFrame(res_svm,\n",
    "                             columns=[\"train_acc\", \"train_auc\", \"test_acc\", \"test_auc\", \"f_classif\", \"mutual_info_classif\", \"pca\", \"n_neighbors\", \"p\"])\n",
    "        \n",
    "        return (res_svm, res_knn)\n",
    "        \n",
    "    def select_best():\n",
    "        res_svm, res_knn = init_search()\n",
    "\n",
    "        res_svm = res_svm.sort_values('train_auc', ascending=False)\n",
    "        res_knn = res_knn.sort_values('train_auc', ascending=False)\n",
    "\n",
    "        ## DATASET_ADCTL\n",
    "        if dataset == DATASET_ADCTL:\n",
    "            res_svm = res_svm[(res_svm['train_auc'] > 0.969) & (res_svm['test_auc'] > 0.888)]\n",
    "            res_knn = res_knn[(res_knn['train_auc'] > 0.969) & (res_knn['test_auc'] > 0.888)]\n",
    "\n",
    "        ## DATASET_ADMCI\n",
    "        elif dataset == DATASET_ADMCI:\n",
    "            res_svm = res_svm[(res_svm['train_auc'] > 0.94) & (res_svm['test_auc'] > 0.73)]\n",
    "            res_knn = res_knn[(res_knn['train_auc'] > 0.97) & (res_knn['test_auc'] > 0.761)]\n",
    "\n",
    "            # res_svm = res_svm[(res_svm['train_auc'] > 0.5) & (res_svm['test_auc'] > 0.5)]\n",
    "            # res_knn = res_knn[(res_knn['train_auc'] > 0.5) & (res_knn['test_auc'] > 0.5)]\n",
    "\n",
    "        ## DATASET_MCICTL\n",
    "        elif dataset == DATASET_MCICTL:\n",
    "            res_svm = res_svm[(res_svm['train_auc'] > 0.884) & (res_svm['test_auc'] > 0.801)]\n",
    "            res_knn = res_knn[(res_knn['train_auc'] > 0.884) & (res_knn['test_auc'] > 0.801)]\n",
    "\n",
    "        res_svm = res_svm.sort_values('test_auc', ascending=False)\n",
    "        res_knn = res_knn.sort_values('test_auc', ascending=False)\n",
    "\n",
    "        no_res = 0\n",
    "        if res_svm.shape[0] == 0:\n",
    "            print(\"NO SVM RESULTS\")\n",
    "            no_res +=1\n",
    "\n",
    "        if res_knn.shape[0] == 0:\n",
    "            print(\"NO KNN RESULTS\")\n",
    "            no_res +=1\n",
    "\n",
    "        if no_res == 2:\n",
    "            print(\"NO RESULT WAS FOUND\")\n",
    "            return None\n",
    "\n",
    "        best_result_knn = res_knn.iloc[0].tolist() \n",
    "        best_result_svm = res_svm.iloc[0].tolist()\n",
    "\n",
    "        if best_result_knn[3] > best_result_svm[3]:\n",
    "           print(\"KNN:\")\n",
    "           print(\"train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca    n_neighbors    p\")\n",
    "           print(best_result_knn)\n",
    "           return best_result_knn\n",
    "            \n",
    "        else:\n",
    "           print(\"SVM:\")\n",
    "           print(\"train_acc        test_acc       train_auc     test_auc   f_classif   mutual_info_classif    pca    n_neighbors    p\")\n",
    "           print(best_result_svm)\n",
    "           return best_result_svm\n",
    "\n",
    "    select_best()\n",
    "\n",
    "\n",
    "# DATASET_ADCTL | DATASET_ADMCI | DATASET_MCICTL\n",
    "# find_best_features_and_classifier(DATASET_ADCTL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
